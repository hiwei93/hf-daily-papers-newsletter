# 【2023-09-26】Huggingface 每日论文速览

- [Huggingface Daily Papers 2023-09-26](https://huggingface.co/papers?date=2023-09-26) 共推荐 6 篇论文。

> 💡说明：
>
> - 本文对 Huggingface Daily Papers 推荐的论文从：主要工作、主要两点、关键词和评估四个方面进行速览。
>
> - 论文的速览内容基于论文的摘要，使用 GPT-4 进行内容生成，然后使用程序将内容整合，并以 Markdown 文本呈现。

## Exploring Large Language Models' Cognitive Moral Development through  Defining Issues Test

1. **本文的主要工作：**

该研究通过建立心理学与人工智能之间的联系，提出了一种有效的评价框架，以帮助刻画大型语言模型在道德一致性和科尔伯格的道德发展阶段方面的道德推理能力。为此，他们使用了一种心理测量工具--定义问题测试。

2. **本文工作的主要亮点：**

文章的创新之处在于将人类心理学与人工智能相整合，用心理领域的工具和理论来评估和理解AI模型的道德推理能力。这种基于心理学的评估框架，不仅帮助我们深入理解AI模型的道德发展和判断，同时也提高了对AI的道德推理能力评估的准确性。

3. **核心关键词：**

- Large Language Models (大型语言模型)

- Cognitive Moral Development (认知道德发展)

- Ethical Reasoning Abilities (道德推理能力)

- Evaluation framework (评价框架)

- Defining Issues Test (定义问题测试)

4. **打分：**

- 实用性: 4/5

- 创新性: 5/5

- 推荐度: 4/5

对于实践者和研究者来说，理解和评估AI模型的道德推理能力特别重要，而本文提供了一个全新的框架和方法。然而，将这种理论投入到实际应用中可能还需要进一步的工作，因此实用性打分为4分。然后，该工作在捕捉AI道德推理能力方面打破了传统框架，实现了理论上的重大突破，因此创新性网满分。最后，由于其在AI道德推理研究中的潜力和影响力，推荐度得分为4分。

[到 Huggingface 论文主页查看详情](https://huggingface.co/papers/2309.13356)

## DeepSpeed-VisualChat: Multi-Round Multi-Image Interleave Chat via  Multi-Modal Causal Attention

**1. 本文主要工作**

本文提出了一个名为DeepSpeed-VisualChat的框架，旨在优化大型语言模型 (Large Language Models，LLM)，并引入了多模态能力。关注点在于提高大型视觉和语言模型处理交错输入的能力。本文通过混合现有数据集上的数据，支持多轮和多图像的对话，并引入了一种创新的多模态因果注意机制。

**2. 工作的主要亮点**

- 首次开源支持处理多轮、多图像对话

- 提出创新的多模态因果关注机制

- 利用混合数据技术确保在多轮、多图像对话中无缝交互

- 相较于现有的框架，DeepSpeed-VisualChat展示了更优的扩展性，支持到达700B参数规模的语言模型

**3. 核心关键词**

- `Large Language Models` (`大型语言模型`)

- `Multi-modal` (`多模态`)

- `Causal Attention Mechanism` (`因果注意力机制`)

- `Data Blending` (`数据混合`)

- `Scalability` (`可扩展性`)

**4. 评分**

- 实用性：4.5/5。DeepSpeed-VisualChat框架旨在解决现有多模态模型在处理交错图像和文本输入时的限制，例如资源分配和数据访问，这大大增加了其应用的实用性。

- 创新性：5/5。本文提出了一种创新的多模态因果注意机制和数据混合技术，是大型多模态语言模型领域的重要进步。

- 推荐度：4.5/5。鉴于其在因果注意力机制和数据混合技术的创新之处，以及框架开源的实用价值，极力推荐读者阅读此篇文章。

[到 Huggingface 论文主页查看详情](https://huggingface.co/papers/2309.14327)

## SCREWS: A Modular Framework for Reasoning with Revisions

### 本文工作总结

1. **本文主要工作**

   本文提出了一个名为SCREWS的模块化修正理论框架，用于改进大型语言模型（LLMs）的输出精度。SCREWS包含三个主要模块：采样、有条件的重新采样和选择，每个模块都由可以根据任务手动选择的子模块组成。作者通过一系列的实验结果验证了该框架的效果并发现了一些新的改进策略。

2. **本文工作的主要亮点**

   SCREWS不仅统一了既有的多种方法于一体，而且还揭示出了一些新的策略用于识别改进的推理链条。在不同的推理任务如数学词题、多跳问题回答以及代码调试等上，SCREWS框架经过与ChatGPT和GPT-4等最新LLMs的测试，均取得了显著成效。

3. **核心关键词**

   - Large Language Models (大型语言模型)

   - SCREWS (SCREWS框架)

   - Revisions (修正)

   - Reasoning Strategies (推理策略)

   - Sampling and Conditional Resampling (采样和有条件的重新采样)

4. **打分**

   - 实用性： 4.5/5分

   - 创新性： 4/5分

   - 推荐度：4.5/5分

   本框架具备较高的实用性，细分任务级别的模块选择为更切实的任务需求提供了可能。从创新性角度上讲，本文并没有提出全新的方法，而是在既有的基础上进行了整合和改进。从推荐度上看，SCREWS框架对于理解和改进大型语言模型的推理能力具有很大的参考价值。

[到 Huggingface 论文主页查看详情](https://huggingface.co/papers/2309.13075)

## Small-scale proxies for large-scale Transformer training instabilities

### 1. 介绍本文的主要工作

本文专注于复现和研究大规模Transformer模型训练中出现的不稳定性。作者均衡对比了学习率与损失率并发现，这些不稳定性在用高学习率训练小模型时也会出现，同时，原先用来应对大规模训练不稳定性的缓解措施在这种情况下同样有效。研究不仅侧重于损失率对学习率变动的敏感性，同时关注了优化器和模型调整在其中发挥的作用。最后，文章通过研究模型激活和梯度规范的扩展行为，预测不稳定性可能出现的情况。

### 2. 本文工作的主要亮点

本文的亮点在于，它成功地在小规模模型中复现并研究了大规模训练的不稳定性。同时，文章探究了各种优化器和模型调整对训练稳定性的影响，对决定学习率的微妙性进行了深入研究。研究还发现，通过检查模型激活和梯度规范的扩展行为，可以预测出不稳定性可能出现的情况。

### 3. 核心关键词

- Transformer (`变压器`)

- Learning Rate (`学习率`)

- Training Stability (`训练稳定性`)

- Optimizer (`优化器`)

- Gradient Norms (`梯度规范`)

### 4. 从实用性、创新性和推荐度进行打分

实用性：4/5 - 训练稳定性是深度学习中的核心议题，这份研究提供了深入理解和有效方法。

创新性：4/5 - 该文章通过在小规模模型中模拟大规模训练的不稳定性，这种方法体现了明显的创新。

推荐度：4/5 - 对于深度学习和自然语言处理的研究者或从业者来说，这篇文章的内容相当有价值。

[到 Huggingface 论文主页查看详情](https://huggingface.co/papers/2309.14322)

## VidChapters-7M: Video Chapters at Scale

**1. 本文主要工作：**

该论文针对长视频章节分割这一重要且研究不充分的主题，提出了一个新的数据集：VidChapters-7M。这是一个由817K个用户章节视频构成的数据集，总共包含700万个章节。这个数据集是通过抓取用户注释的章节在线视频，以一种可扩展的方式来自动创建的，无需任何额外的手动标注。该论文还提出了三个新的任务：视频章节生成、给定真实边界的视频章节生成以及给定其注释标题的视频章节定位。实验使用了简单的基线和最先进的视频-语言模型，结果表明在零样本和微调设置下，VidChapters-7M的预训练可以很好地转移到密集视频字幕任务中，显著提高了在YouCook2和ViTT基准上的最新技术状态。

**2. 本文工作的主要亮点：**

- 创建了一个全新、大规模的长视频章节分割数据集VidChapters-7M，弥补了这一领域公开数据集的空白。

- 提出了三个基于该数据集的新任务，进一步研究长视频分割问题。

- 进行的实验表明，预训练的模型能有效地应用于其他密集视频字幕任务，并得到显著的效果提升。

**3. 核心关键词：**

- `VidChapters-7M` (`VidChapters-7M数据集`)

- `Video Chapter Generation` (`视频章节生成`)

- `Video Chapter Grounding` (`视频章节定位`)

- `Machine Learning` (`机器学习`)

- `Video-Language Models` (`视频-语言模型`)

**4. 评分：**

- 实用性：5分。不仅为学者提供了长期缺乏的视频章节数据集，而且证明了该数据集在实际应用中的有效性，例如密集视频字幕任务。

- 创新性：4分。既提出了新的数据集，也定义了三个新的基于该数据集的任务，加深了对视频分割问题的理解。

- 推荐度：5分。论文结果令人振奋，对于研究者和实践者来说，绝对值得一读。

[到 Huggingface 论文主页查看详情](https://huggingface.co/papers/2309.13952)

## Calibrating LLM-Based Evaluator

### 论文总结

**1. 本文的主要工作：**

本研究探讨了如何对基于大型语言模型(LLMs)的评估器进行校正，使其更好地符合人类偏好。作者提出了一种名为“AutoCalibrate”的多阶段、无梯度方法，该方法采用一套人类标签隐式包含人类偏好，并利用少量案例学习来制定一套初始的评分标准。接着，通过自我优化重制这套标准。研究在多个文本质量评估数据集上的实验结果显示，通过校正可以显著提升与专家评估的相关性，并对有效评分标准的本质进行了深入的洞察。

**2. 本文工作的主要亮点：**

- 提出了一种全新的、无梯度的、名为AutoCalibrate的自动校正方法，能够显著提升模型评估与人类评估的相关性；

- 作为与人类评估竞争的替代选项，研究展示了基于大型语言模型的评估器的力量；

- 在多个数据集上进行了实验证明，完整的定量和定性分析以提供关于有效评分标准的深入直观理解。

**3. 核心关键词：**

- `LLMs (Large Language Models)` (大型语言模型)

- `Reference-free evaluator` (无参考评估器)

- `AutoCalibrate` (自动校正)

- `In-Context Learning` (上下文学习)

- `Scoring Criteria` (评分标准)

**4. 速评（满分5分）：**

- 实用性：4.5分。这项研究解决了大型语言模型评估的实用问题，并为其他研究人员在此领域的工作奠定了基础。

- 创新性：5分。提出了一种全新的无梯度自动校正方法，并在多个数据集上验证了其益处。

- 推荐度：4.5分。片面地考虑，我会强烈推荐这篇论文，因为它旨在解决实际问题，并为此采用了创新的方法。

[到 Huggingface 论文主页查看详情](https://huggingface.co/papers/2309.13308)