# 【2023-09-25】Huggingface 每日论文速览

- [Huggingface Daily Papers 2023-09-25](https://huggingface.co/papers?date=2023-09-25) 共推荐 5 篇论文。

> 💡说明：
>
> - 本文对 Huggingface Daily Papers 推荐的论文从：主要工作、主要两点、关键词和评估四个方面进行速览。
>
> - 论文的速览内容基于论文的摘要，使用 GPT-4 进行内容生成，然后使用程序将内容整合，并以 Markdown 文本呈现。

## CodePlan: Repository-level Coding using LLMs and Planning

### 1. 介绍本文的主要工作

本文针对需要对整个代码库进行普遍性修改的软件工程任务，提出了一种称为"CodePlan"的任务无关框架。工具如 GitHub Copilot，虽然能解决定位到具体代码的编程问题，但对于在整个库级别上变动的任务（我们将这类任务称为“库级别编程任务”），已有的大规模语言模型（LLMs）并不能直接解决。CodePlan 将一个库级编程任务转化为一个规划问题，并通过产生一个多步骤的修改链（plan）进行解决，每一步修改都是通过调用 LLM 产生的，而调用的上下文又来自整个代码库，之前的代码修改和针对当前任务的具体说明。

### 2. 本文工作的主要亮点

本文的主要亮点在于提出了一个新的任务无关框架 - CodePlan，它能处理更复杂、涉及更大规模代码库修改的问题。这个框架通过灵活组合增量依赖性分析、变更可能影响分析以及一种自适应规划算法的新颖方式，极大地拓广了大型语言模型在处理代码修改任务时的能力。通过在多个代码库上评估，证实了 CodePlan 与已有方法相比，能更好地匹配实际情况，并成功让更多库通过有效性检查。

### 3. 核心关键词

- `Large Language Models (大规模语言模型)`

- `CodePlan (代码规划)`

- `Repository-level Coding (库级编程任务)`

- `Incremental Dependency Analysis (增量依赖性分析)`

- `Adaptive Planning Algorithm (自适应规划算法)`

### 4. 从实用性、创新性和推荐度进行打分

- 实用性：4.5/5，库级编程任务是许多软件工程实践中常遇到的问题，CodePlan 的成功应用有助于自动化处理这些问题，节省大量人工努力。

- 创新性：5/5，CodePlan 将库级编程任务转化为规划问题，采用多步骤修改链来解决，并结合增量依赖性分析和自适应规划算法，是典型的创新型解决方案。

- 推荐度：4.5/5，本文提供了解决复杂库级编程任务的新方法，是值得学习和借鉴的优秀工作。

[到 Huggingface 论文主页查看详情](https://huggingface.co/papers/2309.12499)

## DualToken-ViT: Position-aware Efficient Vision Transformer with Dual  Token Fusion

### 文章总结

1. **主要工作**

   本文提出了一种轻量级且高效的视觉变压器模型DualToken-ViT，该模型充分利用了卷积神经网络(CNNs)和视觉变压器(ViTs)的优点。通过有效地融合来自于卷积结构的带有本地信息的标记和来自于自注意力结构的带有全局信息的标记，我们为了实现了一个高效的注意力结构。此外，我们通过盛装更多的全局信息，使模型在处理视觉任务更具优势。我们在图像分类、对象检测和语义分割任务方面进行了大量实验，以证明DualToken-ViT的有效性。在ImageNet-1K数据集上，不同规模的模型分别实现了75.4％和79.4％的准确度，及仅有0.5G和1.0G FLOPs。

2. **主要亮点**

   本文的主要亮点在于成功创建了一种融合本地和全局信息的轻量级视觉变换器模型。此模型不仅降低了自注意力的计算复杂度，而且通过在所有阶段使用位置感知全局标记，还增强了全局信息的丰富度，使模型更适合进行视觉任务。

3. **核心关键词**

   - `Vision Transformers (ViTs)` (`视觉变换器`)

   - `Convolutional Neural Networks (CNNs)` (`卷积神经网络`)

   - `Self-Attention` (`自注意力`)

   - `Position-Aware Global tokens` (`位置感知全局标记`)

   - `DualToken Fusion` (`双标记融合`)

4. **打分**

   - **实用性：**5/5

   - **创新性：**4/5

   - **推荐度：**5/5

考虑到在图像分类、对象检测和语义分割等任务中的表现，本文的模型展示了明显的实用性。同时，文章所提出的模型结合了CNNs和ViTs的优点，比以往的模型在性能、实用性和效率方面都有所提高，显示出一定的创新性。因此，对于计算机视觉和深度学习领域的研究者和从业者来说，本文极具参考价值，所以推荐度也很高。

[到 Huggingface 论文主页查看详情](https://huggingface.co/papers/2309.12424)

## Robotic Offline RL from Internet Videos via Value-Function Pre-Training

### 1. 本文的主要工作

此篇论文讨论了在机器人强化学习（Reinforcement Learning，RL）中，如何使用大量的人类视频数据进行预训练。研究者开发了一个新系统（V-PTR），它通过时间差分学习（Temporal-Difference Learning）来学习价值函数。这个系统将视频数据预训练的优势和机器人离线强化学习方法（基于多样化的机器人数据）结合起来，从而在处理操作任务时，产生更好表现，更强鲁棒性和广泛的泛化能力的价值函数和策略。

### 2. 本文工作的主要亮点

- 创新提出了一种利用大规模人类视频数据集在机器人离线强化学习中的方法，基于时间差分学习的价值函数学习。

- 所开发的V-PTR系统成功结合了视频数据预训练的优势与基于多样化机器人数据的离线强化学习方法，实现了更出色的表现、更强的鲁棒性和广泛的泛化能力。

- 在实际的WidowX机器人上进行的一系列操作任务中，V-PTR展现出了对比其他方法的显著优势。

### 3. 核心关键词

- `Reinforcement Learning` (强化学习)

- `Offline RL` (离线强化学习)

- `Temporal-Difference Learning` (时间差分学习)

- `Robotics` (机器人技术)

- `Value-Function Pre-Training` (价值函数预训练)

### 4. 打分

实用性：5/5

- 这项工作开拓了新的领域，即使用大规模视频数据来预训练机器人离线强化学习。具有广阔的应用前景，可预期在未来的机器人任务执行中有很高的实用性。

创新性：5/5

- 本文创新地提出了一种基于时间差分学习的价值函数预训练方法，结合了视频预训练和机器人离线强化学习，在强化学习研究中具有很好的创新性。

推荐度：5/5

- 这篇文章开启了一种新的使用人类视频数据进行机器人离线强化学习的探索路径，有可能推动整个领域的发展，对于在这个领域的研究者和从事相关技术开发的工程师来说，极力推荐阅读。

[到 Huggingface 论文主页查看详情](https://huggingface.co/papers/2309.13041)

## MosaicFusion: Diffusion Models as Data Augmenters for Large Vocabulary  Instance Segmentation

### 本文总结

#### 1. 介绍本文的主要工作

本文提出了一个名为MosaicFusion的数据增强方法，用于大词汇量实例分割。这种方法无需训练，且不依赖于任何标签监督。MosaicFusion能够产生大量的合成标签数据，以便对稀有和新颖的类别进行建模。本文的实验结果表明，MosaicFusion可以显著提高现有实例分割模型的性能，特别是对于稀有和新颖的类别。

#### 2. 本文工作的主要亮点

本文的主要亮点在于提出了一种基于扩散模型的简单而有效的数据增强方法，无需训练和标签监督。设计了两种关键的方法：首先,将图像画布划分为若干区域，进行一轮扩散过程，在不同的文字提示条件下同时生成多个实例。其次，通过聚合与物体提示相关的跨层次和扩散时间步的注意力图，然后进行简单的阈值设定和边缘感知的再细化处理，获取相应的实例掩码。它能够大规模地产生对稀有和新颖类别有效的合成标签数据。

#### 3. 核心关键词

- `MosaicFusion` (马赛克融合)

- `Diffusion Models` (扩散模型)

- `Data Augmentation` (数据增强)

- `Instance Segmentation` (实例分割) 

- `Large Vocabulary` (大词汇量)

#### 4. 评分

##### 实用性：5分

MosaicFusion的应用性强，可以大幅度提高稀有和新颖类别的实例分割模型的性能。由于无需训练和标签监督，降低了使用门槛。

##### 创新性：4分

MosaicFusion采用了一种新颖的基于扩散模型的数据增强方法，并且开创性地通过两种设计用来获取实例和掩码。但其主要基于已有的文本到图像的扩散模型。

##### 推荐度：5分

MosaicFusion在改进实例分割模型性能、尤其在处理稀有和新颖类别的任务上展现了显著效果。强烈推荐给需要处理实例分割问题的研究者和工程师使用。

[到 Huggingface 论文主页查看详情](https://huggingface.co/papers/2309.13042)

## Dynamic ASR Pathways: An Adaptive Masking Approach Towards Efficient  Pruning of A Multilingual ASR Model

### 论文总结

1. **本文主要工作**

本文提出了一种适应性掩膜方法，结合两种不同的剪枝场景，用于有效压缩多语言自动语音识别（ASR）模型。新方法可以动态地调整子网络，避免过早决定固定子网络的结构。两种剪枝场景分别产生稀疏的单语言模型或稀疏的多语言模型（称为Dynamic ASR Pathways）。该方法通过从不同的子网络初始化进行适应，联合发现并训练了更优的子网络（路径），从而减少了对特定语言剪枝的需求。

2. **本文工作的主要亮点**

- 剪枝的同时实现了模型性能的最小化损失，并避免了为每种语言都需要进行多轮剪枝和重新训练的过程。

- 提出的Dynamic ASR Pathways方法在构建稀疏的单语言模型时，优于现有的剪枝方法。

- 新方法还可以同时发现并训练一个多语言模型的更优子网络，降低了特定语言剪枝的需求。

3. **核心关键词**

   - Neural Network Pruning (`神经网络剪枝`)

   - Multilingual ASR model (`多语言ASR模型`)

   - Adaptive Masking Approach (`适应性掩膜方法`)

   - Dynamic ASR Pathways (`动态ASR路径`)

   - Sub-network (`子网络`)

4. **评分**

   - **实用性:** 4.5/5. 该研究对多语言ASR模型的剪枝十分实用，能够大大提高模型的效率和适用性。然而，其在处理单一语言模型时可能需要进一步的改善和评估。

   - **创新性:** 4/5. 本文提出的Dynamic ASR Pathways方法具有一定的创新性，它通过动态适应子网络，改进了现有的剪枝方法。但是，适应性掩膜技术的应用仍然依赖于其他现有技术。

   - **推荐度:** 4.5/5. 对于工作在自动语音识别（ASR）领域的研究者，本文的方法为提高多语言ASR模型的效率提供了新的

[到 Huggingface 论文主页查看详情](https://huggingface.co/papers/2309.13018)